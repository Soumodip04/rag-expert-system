# Environment Variables for RAG Expert System - API Models Configuration

# =============================================================================
# API-BASED MODEL CONFIGURATION
# =============================================================================

# Choose your preferred API-based model by uncommenting one of the sections below:

# -----------------------------------------------------------------------------
# OPTION 1: OpenAI GPT Models (Paid, High Quality)
# -----------------------------------------------------------------------------
# LLM_MODEL=gpt-3.5-turbo
# USE_LOCAL_MODEL=false
# OPENAI_API_KEY=your_openai_api_key_here

# Available OpenAI models:
# - gpt-3.5-turbo (fastest, cheapest)
# - gpt-4 (best quality, slower)
# - gpt-4-turbo (best balance)
# - gpt-4o (latest)

# -----------------------------------------------------------------------------
# OPTION 2: Groq API (FREE Tier Available, Fast)
# -----------------------------------------------------------------------------
LLM_MODEL=groq
USE_LOCAL_MODEL=false
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant

# Available Groq models:
# - llama-3.1-8b-instant (fastest, free)
# - llama-3.1-70b-versatile (better quality, free)
# - gemma-7b-it (alternative option)

# -----------------------------------------------------------------------------
# OPTION 3: Anthropic Claude (Paid, High Quality)
# -----------------------------------------------------------------------------
# LLM_MODEL=claude
# USE_LOCAL_MODEL=false
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Available Claude models:
# - claude-3-haiku (fastest, cheapest)
# - claude-3-sonnet (balanced)
# - claude-3-opus (best quality)

# =============================================================================
# VECTOR STORE AND EMBEDDING CONFIGURATION (These stay local for privacy)
# =============================================================================

VECTOR_STORE_TYPE=chroma
EMBEDDING_MODEL=sentence-transformers

# =============================================================================
# DOCUMENT PROCESSING CONFIGURATION
# =============================================================================

CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CHUNKS_PER_QUERY=5

# =============================================================================
# OPTIONAL: ADDITIONAL API CONFIGURATIONS
# =============================================================================

# Pinecone Configuration (optional vector store)
# PINECONE_API_KEY=your_pinecone_api_key_here
# PINECONE_ENVIRONMENT=your_pinecone_environment

# Weaviate Configuration (optional vector store)
# WEAVIATE_URL=http://localhost:8080
# WEAVIATE_API_KEY=your_weaviate_api_key

# Cohere Configuration (optional embedding model)
# COHERE_API_KEY=your_cohere_api_key_here

# =============================================================================
# LOGGING AND PRIVACY SETTINGS
# =============================================================================

LOG_LEVEL=INFO
LOG_FILE=logs/rag_system.log

# Privacy and Security
ENABLE_AUDIT_LOGS=true
ANONYMIZE_QUERIES=false

# =============================================================================
# INSTRUCTIONS:
# =============================================================================

# 1. Choose ONE of the API options above by uncommenting it
# 2. Get your API key from the respective provider:
#    - OpenAI: https://platform.openai.com/api-keys
#    - Groq: https://console.groq.com/ (FREE!)
#    - Anthropic: https://console.anthropic.com/
# 3. Replace "your_api_key_here" with your actual API key
# 4. Save this file as ".env" in your project root
# 5. Restart your Streamlit applications

# Note: Your documents and vector store remain local for privacy,
# only the LLM generation uses the API service.
